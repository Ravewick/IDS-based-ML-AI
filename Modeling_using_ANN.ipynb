{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiwHR3-H5oNC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx_dyZdlSXMK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import sklearn\n",
        "import io\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THyNO1v5Mzrx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "train_url = '/content/drive/My Drive/IDS/NSL_KDD_Train.csv'\n",
        "test_url = '/content/drive/My Drive/IDS/NSL_KDD_Test.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utaaqng3NOY0"
      },
      "outputs": [],
      "source": [
        "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
        "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
        "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
        "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
        "\n",
        "\n",
        "df = pd.read_csv(train_url,header=None, names = col_names)\n",
        "\n",
        "df_test = pd.read_csv(test_url, header=None, names = col_names)\n",
        "\n",
        "print('Dimensions of the Training set:',df.shape)\n",
        "print('Dimensions of the Test set:',df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zKWRUDkWpiH"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVvbmDNi5jn8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print('Label distribution Training set:')\n",
        "print(df['label'].value_counts())\n",
        "print()\n",
        "print('Label distribution Test set:')\n",
        "print(df_test['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyLnY-XCXVnk",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "print('Training set:')\n",
        "for col_name in df.columns:\n",
        "    if df[col_name].dtypes == 'object' :\n",
        "        unique_cat = len(df[col_name].unique())\n",
        "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
        "\n",
        "print()\n",
        "print('Distribution of categories in service:')\n",
        "print(df['service'].value_counts().sort_values(ascending=False).head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhKXNXlwXb5G"
      },
      "outputs": [],
      "source": [
        "# Test set\n",
        "print('Test set:')\n",
        "for col_name in df_test.columns:\n",
        "    if df_test[col_name].dtypes == 'object' :\n",
        "        unique_cat = len(df_test[col_name].unique())\n",
        "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZKviPW0XnzU"
      },
      "source": [
        "**LabelEncoder**\n",
        "\n",
        "**Insert categorical features into a 2D numpy array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYmvn2qWXxs2"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "categorical_columns=['protocol_type', 'service', 'flag']\n",
        "\n",
        "df_categorical_values = df[categorical_columns]\n",
        "testdf_categorical_values = df_test[categorical_columns]\n",
        "\n",
        "df_categorical_values.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNVa7mN9X1qV",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# protocol type\n",
        "unique_protocol=sorted(df.protocol_type.unique())\n",
        "string1 = 'Protocol_type_'\n",
        "unique_protocol2=[string1 + x for x in unique_protocol]\n",
        "print(unique_protocol2)\n",
        "\n",
        "# service\n",
        "unique_service=sorted(df.service.unique())\n",
        "string2 = 'service_'\n",
        "unique_service2=[string2 + x for x in unique_service]\n",
        "print(unique_service2)\n",
        "\n",
        "\n",
        "# flag\n",
        "unique_flag=sorted(df.flag.unique())\n",
        "string3 = 'flag_'\n",
        "unique_flag2=[string3 + x for x in unique_flag]\n",
        "print(unique_flag2)\n",
        "\n",
        "\n",
        "# put together\n",
        "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
        "\n",
        "\n",
        "#do it for test set\n",
        "unique_service_test=sorted(df_test.service.unique())\n",
        "unique_service2_test=[string2 + x for x in unique_service_test]\n",
        "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf-QhZyfX9Jd"
      },
      "source": [
        "**Transform categorical features into numbers using LabelEncoder()**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta0CsfRUX5Tg",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
        "\n",
        "print(df_categorical_values.head())\n",
        "print('--------------------')\n",
        "print(df_categorical_values_enc.head())\n",
        "\n",
        "# test set\n",
        "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq_pnkScYDOi"
      },
      "source": [
        "**One-Hot-Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVBytj5dYGDu"
      },
      "outputs": [],
      "source": [
        "enc = OneHotEncoder(categories='auto')\n",
        "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
        "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
        "\n",
        "\n",
        "# test set\n",
        "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
        "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
        "\n",
        "df_cat_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-ZvKY6bS-r"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxTdPirkbW-V"
      },
      "outputs": [],
      "source": [
        "trainservice=df['service'].tolist()\n",
        "testservice= df_test['service'].tolist()\n",
        "difference=list(set(trainservice) - set(testservice))\n",
        "string = 'service_'\n",
        "difference=[string + x for x in difference]\n",
        "difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpBVYECtcN02"
      },
      "outputs": [],
      "source": [
        "for col in difference:\n",
        "    testdf_cat_data[col] = 0\n",
        "\n",
        "print(df_cat_data.shape)\n",
        "print(testdf_cat_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vsl_YcrcSd8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOXgIdAZcVAF"
      },
      "outputs": [],
      "source": [
        "newdf=df.join(df_cat_data)\n",
        "newdf.drop('flag', axis=1, inplace=True)\n",
        "newdf.drop('protocol_type', axis=1, inplace=True)\n",
        "newdf.drop('service', axis=1, inplace=True)\n",
        "\n",
        "# test data\n",
        "newdf_test=df_test.join(testdf_cat_data)\n",
        "newdf_test.drop('flag', axis=1, inplace=True)\n",
        "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
        "newdf_test.drop('service', axis=1, inplace=True)\n",
        "\n",
        "print(newdf.shape)\n",
        "print(newdf_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "706-Qqhycc_-"
      },
      "outputs": [],
      "source": [
        "labeldf=newdf['label']\n",
        "labeldf_test=newdf_test['label']\n",
        "\n",
        "\n",
        "# change the label column\n",
        "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
        "                           'ipsweep' : 1,'nmap' : 1,'portsweep' : 1,'satan' : 1,'mscan' : 1,'saint' : 1,\n",
        "                            'ftp_write': 1,'guess_passwd': 1,'imap': 1,'multihop': 1,'phf': 1,'spy': 1,'warezclient': 1,'warezmaster': 1,'sendmail': 1,'named': 1,'snmpgetattack': 1,'snmpguess': 1,'xlock': 1,'xsnoop': 1,'httptunnel': 1,\n",
        "                           'buffer_overflow': 1,'loadmodule': 1,'perl': 1,'rootkit': 1,'ps': 1,'sqlattack': 1,'xterm': 1 })\n",
        "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
        "                           'ipsweep' : 1,'nmap' : 1,'portsweep' : 1,'satan' : 1,'mscan' : 1,'saint' : 1\n",
        "                           ,'ftp_write': 1,'guess_passwd': 1,'imap': 1,'multihop': 1,'phf': 1,'spy': 1,'warezclient': 1,'warezmaster': 1,'sendmail': 1,'named': 1,'snmpgetattack': 1,'snmpguess': 1,'xlock': 1,'xsnoop': 1,'httptunnel': 1,\n",
        "                           'buffer_overflow': 1,'loadmodule': 1,'perl': 1,'rootkit': 1,'ps': 1,'sqlattack': 1,'xterm': 1})\n",
        "\n",
        "\n",
        "# put the new label column back\n",
        "newdf['label'] = newlabeldf\n",
        "newdf_test['label'] = newlabeldf_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62apvPp45joC",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "X_Df = newdf.drop('label',axis=1)\n",
        "newdf.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvi-Oglzc5Bs"
      },
      "source": [
        "**Step 2: Feature Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VeQhD09c6qT"
      },
      "outputs": [],
      "source": [
        "Y_Df = newdf.label\n",
        "X_Df_test = newdf.drop('label',axis=1)\n",
        "Y_Df_test = newdf_test.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfC3uKfe5joD"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "y_binary = to_categorical(Y_Df)\n",
        "y_test_binary = to_categorical(Y_Df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nWS5oukdFS6"
      },
      "outputs": [],
      "source": [
        "colNames=list(X_Df)\n",
        "colNames_test=list(X_Df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-n3hi1G5joD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "X_Df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvBZ7RXa5joD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "X_Df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FEBafDjodRcT",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "scaler1 = preprocessing.StandardScaler().fit(X_Df)\n",
        "X_Df=scaler1.transform(X_Df)\n",
        "\n",
        "scaler5 = preprocessing.StandardScaler().fit(X_Df_test)\n",
        "X_Df_test=scaler5.transform(X_Df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XCyNsy935joE",
        "outputId": "c94132f4-ef4e-4146-9e99-80560a395e81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.11024922, -0.0076786 , -0.00491864, ..., -0.01972622,\n",
              "         0.82515007, -0.04643159],\n",
              "       [-0.11024922, -0.00773737, -0.00491864, ..., -0.01972622,\n",
              "         0.82515007, -0.04643159],\n",
              "       [-0.11024922, -0.00776224, -0.00491864, ..., -0.01972622,\n",
              "        -1.21190076, -0.04643159],\n",
              "       ...,\n",
              "       [-0.11024922, -0.00738219, -0.00482315, ..., -0.01972622,\n",
              "         0.82515007, -0.04643159],\n",
              "       [-0.11024922, -0.00776224, -0.00491864, ..., -0.01972622,\n",
              "        -1.21190076, -0.04643159],\n",
              "       [-0.11024922, -0.00773652, -0.00491864, ..., -0.01972622,\n",
              "         0.82515007, -0.04643159]])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W8yWyixy5joE",
        "outputId": "2358cdf0-bc04-4120-e17c-444d388f7e60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.11024922, -0.0076786 , -0.00491864, ..., -0.01972622,\n",
              "         0.82515007, -0.04643159],\n",
              "       [-0.11024922, -0.00773737, -0.00491864, ..., -0.01972622,\n",
              "         0.82515007, -0.04643159],\n",
              "       [-0.11024922, -0.00776224, -0.00491864, ..., -0.01972622,\n",
              "        -1.21190076, -0.04643159],\n",
              "       ...,\n",
              "       [-0.11024922, -0.00738219, -0.00482315, ..., -0.01972622,\n",
              "         0.82515007, -0.04643159],\n",
              "       [-0.11024922, -0.00776224, -0.00491864, ..., -0.01972622,\n",
              "        -1.21190076, -0.04643159],\n",
              "       [-0.11024922, -0.00773652, -0.00491864, ..., -0.01972622,\n",
              "         0.82515007, -0.04643159]])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xGAZuhCZ5joE"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "y_binary = to_categorical(Y_Df)\n",
        "y_test_binary = to_categorical(Y_Df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD0ODueo5joE"
      },
      "source": [
        "#   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIk1Bjol5joE"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HrFDpvlY5joE"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from IPython.display import SVG\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "evj61qla5joF",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, kernel_initializer='normal'))\n",
        "model.add(Dense(2, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JfXY-unR5joF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import F1Score, Precision, Recall\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', F1Score(), Precision(), Recall()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YMn9kORL5joF"
      },
      "outputs": [],
      "source": [
        "# overfitting, underfitting\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.keras\", verbose=0, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQaPgLeD5joF",
        "outputId": "cc19ebea-3e98-4f77-e076-623f691b9a3c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "491/886 [===============>..............] - ETA: 5s - loss: 0.0539 - accuracy: 0.9829 - f1_score: 0.9828 - precision_1: 0.9829 - recall_1: 0.9829"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_Df, y_binary, batch_size=128, epochs=50, verbose=1, validation_split=0.1 ,callbacks=[monitor])\n",
        "\n",
        "f1_val = history.history['val_f1_score'][-1]\n",
        "precision_val = history.history['val_precision'][-1]\n",
        "recall_val = history.history['val_recall'][-1]\n",
        "\n",
        "print(f\"F1 Score (Validation): {f1_val}\")\n",
        "print(f\"Precision (Validation): {precision_val}\")\n",
        "print(f\"Recall (Validation): {recall_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QaSEX6tQxNHn"
      },
      "outputs": [],
      "source": [
        "len(Y_Df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1x_NHJaYv1tu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#y_pred = model.predict_classes(X_Df_test)  # Assuming multi-class problem (change to predict for binary)\n",
        "y_pred = model.predict(X_Df_test)  # Assuming multi-class problem (change to predict for binary)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "cm = confusion_matrix(Y_Df_test, y_pred)\n",
        "\n",
        "#cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "#cm_normalized = cm.astype('float') / 22544\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "#print(cm_normalized)\n",
        "\n",
        "print(cm)\n",
        "\n",
        "target_names=[\"Normal\", \"DoS\",  \"Probe\", \"R2L\", \"U2R\"]\n",
        "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=target_names, yticklabels=target_names,cmap='Blues')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show(block=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lbWfSEisv9n1"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title(\"Plot of accuracy vs epoch for train and test dataset\")\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9vZSztIv-Eg"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title(\"Plot of loss vs epoch for train and test dataset\")\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}